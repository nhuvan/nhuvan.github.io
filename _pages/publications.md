---
layout: archive
title: "Research & Publications"
permalink: /publications/
author_profile: true
---

## Research

Mes recherches se focalisent autour de deux thématiques :

### La fouille multimodale de bases d'images et de vidéos
Au cours de ma thèse, j'ai pu approfondir mes connaissances dans le domaine de l'indexation et de la recherche interactive d'images par le contenu au travers d'un projet porteur (avec les professeurs Jean-Marc Ogier, Salvatore Tabbone et  Alain Boucherde l'AUF). Le projet IDEA (Images of natural Disasters from robot Exploration in urban Area) financé par le programme STIC-Asie, se positionnait sur le thème du traitement d’images et l’extraction de contenu pour la gestion des informations collectées par des robots patrouillant dans les zones urbaines dans une situation de post-catastrophe.

Mon sujet de recherche était l'indexation et la recherche d'images par le contenu. Pendant cette période, j'ai réalisé plusieurs taches: 1) une revue des caractéristiques visuelles utilisé dans le domaine de la recherche par le contenu (signatures globales, signatures locales) ; 2) le développement de méthodes de recherche interactive d'images à court-terme ; 3) le développement de méthodes d'indexation et de recherche interactive d'images à long-terme ; 4) une visualisation des résultats de recherche d'images multimodale.

Ce travail a donné lieu à 2 articles de revues (SRJ rank Q2), 5 publications dans des manifestations internationales avec comité de lecture et 1 manifestation nationale avec comité de lecture. Le résultat de mon travail est un système d'extraction des caractéristiques visuelles (couleur, texture, forme) ; une nouvelle méthode de retour de pertinence qui combine les techniques du mouvement du point de requête et de l'extension de requêtes ; un système d'apprentissage interactif qui associe des mots clés avec des caractéristiques visuelles ; une interface permettant la visualisation et l'interrogation mixte textuelle/visuelle.

Parmi ces résultats, la contribution la plus significative a été la proposition d'une nouvelle approche pour apprendre des représentations visuelles de keywords (concepts textuels) en profitant des connaissances d'experts via l'interaction. C'est une méthode d'apprentissage interactive à long-terme : les connaissances du système proposé sont améliorées via des interactions tout au long de la vie du système. \\

Par la suite, dans le  cadre  de  mon  premier  contrat  d’ingénieur  de  recherche (avec le prof. Jean-Marc Ogier), je me suis impliqué dans le projet PEDIVHANDI (Pédagogie et Diversité des Apprenants avec Priorité au Handicap) financé par le Fonds Européen de Développement Régional (FEDER). L’idée principale était d’analyser les contenus audiovisuels et documentaires par des techniques issues de l’analyse du signal et de l’image. Ces contenus multimédia sont le résultat de l’acquisition par différentes modalités : webcam issues de tablettes ou de PC, flux vidéo issus d’un système de visio-conférence...
Dans le carde de ce projet, mon objectif était d'explorer des méthodes d'indexation et de recherche multimodale de vidéos de cours. J'ai travaillé également avec différentes techniques  de traitement d'images : l'analyse de la mise en page, la séparation objets/fond, la détection de texte et de graphiques. 

Les publications de mon travail pendant cette période sont 1 article revue (SRJ rank Q2), 3 participations à des manifestations internationales avec comités de lecture et un dépôt à l'APP (Agence pour la Protection des Programmes). Le résultat de mon travail est un système d'indexation des vidéos de cours. Cette indexation multimodale se fait avec 2 modalités : le contenu textuel qui vient de l'OCR des diapos et la reconnaissance vocale ; le contenu visuel venant des graphiques dans les diapos. J'ai par ailleurs collaboré avec La SATT Grand Centre pour faire un dépôt APP du système PEVIHANDI. Par la suite, j'ai travaillé à La SATT Grand Centre (10/2014-04/2016) dans l'objectif de transférer cette innovation vers l'industrie. J'ai quitté La SATT en 04/2016 après avoir fini la phase de maturation du système : La SATT était alors en négociation pour vendre une licence du système à une société à Paris.

### L'apprentissage automatique pour la reconnaissances de formes

Le laboratoire L3i, reconnu au niveau international sur l’analyse de document, a lancé en 2011 le projet e-bdthèque dont l’objectif est de valoriser les corpus de Bande Dessiné numérisées. J'ai commencé mon deuxieme postdoc dans l'équipe BD en 04/2016 (avec le prof. Jean-Christophe Burie, prof. Arnaud Revel et prof Karell Bertet). Dans ce contexte, j'ai travaillé principalement sur la détection automatique de cases de BD, de bulles, de dialogues, du texte, des personnages et des décors. 

Nombre de verrous scientifiques sont encore à lever pour aller bien au-delà des méthodes classiques d’analyse (extraction de caractéristiques, analyse structurelles ou statistiques, approches à base de graphes…) donnant des résultats mitigés. Je commence à me tourner vers de nouvelles approches, issues notamment des méthodes d’apprentissage profonds (deep learning, réseaux de neurones), qui ouvrent de nouvelles opportunités.
En pratique, je construis des algorithmes d’analyse d'images de BD se basant sur l'apprentissage profond, en les combinant avec des algorithmes de traitement d'images classique, et priotiser le contexte semi-supervisé.

Les publications de mon travail dans ce projet (jusqu'à maintenant) sont 2 article de revues (1 SRJ Q2), 1 article soumis à une revue SRJ Q1 et 3 manifestations internationales avec comités de lecture. Les résultats de ce travail sont des méthodes supervisées d'apprentissage profond pour détecter et segmenter des cases ; segmenter des bulles, détecter des personnages et l'association de personnages et des bulles. J'ai focalisé également ma recherche sur un contexte semi-supervisé dans lequel on n'a qu'une partie de données qui sont annotées ou bien des annotations incomplètes. Ce contexte est important parce qu'il se présente dans plusieurs scénarios concrets. De plus, l'apprentissage semi-supervisé peut profiter des résultat d'algorithmes traditionnels pour construire un modèle d'apprentissage automatique sans besoin d'aucune annotation manuelle.\\

Je participe également au groupe de recherche du prof. Antoine Doucet sur la détection et la correction de textes OCR (Optical Character Recognition). Normalement, la reconnaissance de textes n'étant pas parfaite, une étape de post-traitement est nécessaire pour améliorer le texte. J'ai contribué à la recherche des caractéristiques et des méthodes d'apprentissage pour effectuer la détection/correction Post-OCR. Nous avons publié dans 3 manifestations internationales avec comités de lecture (CORE rank A et A*). 

## Publications 

<!-- {% if author.googlescholar %} -->
Most of these publications may also be found on my <u><a href="{{author.googlescholar}}">google scholar profile</a>.</u>
<!-- {% endif %} -->

<!-- <br>If you like the format of the preprints included here, see <u><a href="https://github.com/brenhinkeller/preprint-template.tex">preprint-template.tex</a></u> -->

---
{% include base_path %}
<b>Journals:</b>
<br/>
  <ol>
    {% for post in site.publications reversed %}
      {% if post.journal %}
        {% include archive-single-cv.html %}
      {% endif %}
    {% endfor %}
  </ol>
<br/>


---
<b>Conferences:</b>
<br/>
<ol>{% for post in site.publications reversed %}
      {% if post.journal != "True" %}
        {% include archive-single-cv.html %}
      {% endif %}
    {% endfor %}</ol>
<br/>
