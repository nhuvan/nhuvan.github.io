---
layout: archive
permalink: /
title: "Vincent NGUYEN"
author_profile: true
redirect_from:
  - /news/
---

<!-- Welcome to my website.<br/>
I'm a Computer Vision and Machine Learning researcher/lecturer at the LIFO Lab, University of Orléans.

--- -->

<!-- ### BIO: -->

<!-- I completed my PhD in Computer Vision in 10/2011 under the supervisor of prof. Jean-Marc Ogier, prof. AUF Alain Boucher and prof. Salvatore Tabbone. From 11/2011 to 09/2014 I worked with prof. Jean-Marc Ogier on multimodal indexing for lecture videos. In 2014, the SATT Grand Center chose my invention (the PEDIVHANDI project) for its technology transfer program. From 10/2014 to 04/2016, I focused on this new project (employee at La SATT). From 05/2016 to 08/2018, I worked in the eBD team of prof. Jean-Christophe Burie, doing research on the comic book images analysis using hybric methods (deep learning and traditional image processing/computer vision techniques). From 09/2018, I have been working with prof. Jean-Christophe Burie, prof. Arnaud Revel and prof Karell Bertet in the joint lab S.A.I.L. In this context, I work mainly on the  semi-supervised and weakly supervised learning methods.<br/>
My research focuses on two themes: -->

<!-- I obtained my Phd Computer Vision in 10/2011 at the University of La Rochelle, under the supervisor of Prof. Jean-Marc Ogier, Prof. AUF Alain Boucher and Prof. Salvatore Tabbone. After that, I worked with Prof. Jean-Marc Ogier on multimodal indexing for lecture videos for PEDIVHANDI project, for which I was awarded with SATT sponsorship within its technology transfer program in October, 2014. Our lecture videos indexing system from PEDIVHANDI project is protected by the APP (https://www.app.asso.fr/en). From 2016 I have focused more on the deep learning approach for the field of computer vision and document analysis. I worked in the e-BDthèque team, led by Prof. Jean-Christophe Burie, doing research on the comic book images analysis using hybrid methods. From 09/2018, I have played a key role in developing the joint lab S.A.I.L., leading research projects related to the deep learning approach with Prof. Jean-Christophe Burie, Prof. Arnaud Revel and Prof. Karell Bertet. -->
<!-- 
I obtained my Phd in Computer Vision at the University of La Rochelle, under the supervision of Prof. Jean-Marc Ogier.  I was awarded the SATT sponsorship within its technology transfer program for my work on  on multimodal indexing for lecture videos. Since 2016 I have developed my research path towards the deep learning approach for computer vision and document analysis. I played a key role in developing the joint lab S.A.I.L., leading research projects related to the deep learning approach. From 09/2021, I started to work at the lab LIFO, University of Orléans. -->

Since 09/2021, I have been an associate professor at [l'IUT](https://www.univ-orleans.fr/fr/iut-orleans/formation/informatique) / [University of Orléans](https://www.univ-orleans.fr/fr), France and a member of the research team CA (Constraints and Learning) of [LIFO](https://www.univ-orleans.fr/lifo/). I'm the Director of studies of the second year of bachelor's degree.

My research interests cover several  themes:

+ Incremental / Continual learning.
+ Weakly supervised learning.
+ Robust AI

<!--  -->
<!-- If you have any questions or comments, please feel free to contact me at nhu-van.nguyen (at) univ-lr . fr -->

<span style="color:red">08/2025:</span> Our project ANR PRC EnACA is accepted. <br/>

### Research Grants: 

+ 2026-2029 : ANR EnACA project on AI-based multimodal understanding of comics, manga, and related art forms. The research focuses on generalizable instance segmentation under visual style and domain shift (PI). 
+ 2023-2026: grant CIFRE with <span style="color:blue">[IMPACT](https://sas-impact.fr/en/)</span>. (Co-PI)
+ 2023-2026: APR Optimedias (Artificial intelligence for the benefit of precision medicine in neuropsychiatry and infectiology) funded by the Region Centre-Val-de-Loire, France.
+ 2022-2025 : ANR ASTRID ROV-Chasseur on weakly supervised learning and efficient deep models for robotic vision. (PI)
+ 2022-2023 : ACHS: a scientific collaboration projet of the French Embassy in Vietnam on medical data analysis (PI) 
+ 2015-2016 : eDuc: a technology transfer project funded by the SATT Grand Center on lecture videos indexing (PI)

### Research activities

+ Sep 2023: Organizing a special session at CBMI2023: Cross-modal multimedia analysis and retrieval for well-being insights. Session Chair.
+ Oct 2023: Organizing a special session at KSE2023: Multimodal Data and Multidisciplinary Applications
<!-- + PC member of SoICT2023, MAPR2022, MANPU2022, ICMR 2022, MMM2019 -->

### PhD students / Postdocs

+ Etienne LEHEMBRE, postdoc of the project [JUNON](https://www.junon-cvl.fr/fr), 2024-2025.
+ Rim Rahali, postdoc of the project ROV-Chasseur, 2023-2025.
+ Jean-Daniel De-Ambrogi, "Efficient Deep Models for Indoor Reconstruction and Navigation on Mobile Devices", co-supervisor with  <span style="color:blue">[Aladine Chatouni](http://aladine-chetouani.com)</span>
+ Trung-Anh Dang, "Continual learning", co-supervisor with <span style="color:blue">[Christel Vrain](https://www.univ-orleans.fr/lifo/Members/vrain/)</span>
+ Yen Vu, "Semi- and self-supervised learning with clustering using knowledge. Application to mineral potential mapping", co-supervisor with <span style="color:blue">[Christel Vrain](https://www.univ-orleans.fr/lifo/Members/vrain/)</span> and <span style="color:blue">[Bich Dao](https://www.univ-orleans.fr/lifo/membres/dao/)</span> and <span style="color:blue">[Hugo Breillard - BRGM](https://www.brgm.fr/en)</span>
+ Huy Thong Bui, bourse France Excellence Eiffel, "Federated learning", co-supervisor with <span style="color:blue">[Son VU](https://www.etis-lab.fr/2022/01/13/son-vu/)</span>


### Professional and Community roles:

I am experienced in building real IT systems, especially in building AI products. I have experience as an entrepreneur (co-founder of the startup [BrickIn'Up](/administratives/101-bup/), France) and as an AI advisor for companies worldwide, including an insurtech AI Startup in Germany, two AI solutions companies in Vietnam.

<!-- I am one of key members of the Association of Vietnamese Scientists and Experts ([AVSE Global](http://www.avseglobal.org/)), headquartered in Paris. I have contributed to organizing innovative events gathering Vietnamese excellences all over the world. -->

<!-- + Research Projects: <span style="color:blue">[click here](publications)</span> -->

+ Industrial projects: <span style="color:blue">[click here](industrie)</span>

<!-- ### Contact: -->
<!-- 
+ Offices: C001, Bât. Pascal, Université de La Rochelle, France <br/>
Phone: (+33) 5 46 45 87 62 -->
<!-- + vincent.nguyen (at) insa-lyon . fr -->
<!-- + nhu-van.nguyen (at) univ-lr . fr -->
<!-- + nhuvan.nguyen (at) avseglobal . org -->

<!-- Research projects: -->
---

### past announcements:

+ <span style="color:red">02/2025:</span> 1 article on efficient models accepted in the journal Pattern Analysis and Applications.<br/>

+ <span style="color:red">01/2025:</span> 1 paper on semi-supervised learning accepted at VISAPP 2025.<br/>

+ <span style="color:red">11/2024:</span> 1 paper on PU learning accepted at SAC 2025.<br/>

+ <span style="color:red">10/2024:</span> 1 paper on Continual learning accepted at WACV 2024.<br/>

+ <span style="color:red">10/2023:</span> 1 paper on non-English LLM accepted at EMNLP 2023. A collaboration work with researchers at the WASP Media & Language Arena and the DopikAI lab.<br/>

+ <span style="color:red">7/2023:</span> 1 paper accepted at CBMI 2023.<br/>

+ <span style="color:red">01/2023:</span> We have 3 PhD positions and 3 internship positions in Machine Learning. Please contact us for more information<br/>

+ <span style="color:red">10/2022:</span> Our project APR Optimedias (Artificial intelligence for the benefit of precision medicine in neuropsychiatry and infectiology) is accepted by the Region Centre-Val-de-Loire, France.<br/>

+ <span style="color:red">05/2022:</span> Our project ACHS (Detection of anomalies in the streaming of health data from smartphone sensors) is selected for the Scientific Cooperation program of the French Embassy in Vietnam.<br/>

+ <span style="color:red">03/2022:</span> I am looking for 2 post-docs, in self/semi supervised learning and in efficient deep models, and 2 interns in Computer Vision and/or Machine Learning.<br/>

+ <span style="color:red">12/2021:</span> Our project ROV-Chasseur is accepted (Project ANR Astrid 2021 on Robotic). This project focuses on the self- and semi-supervised learning approach and the design of efficient deep models based on the compression of deep neural networks.<br/>

+ <span style="color:red">09/2021:</span> Since 09/2021 I started to work as associate professor at the [University of Orléans](https://www.univ-orleans.fr/fr).<br/>

+ <span style="color:red">05/2021:</span> Two papers accepted at ICDAR2021, CORE rank A.<br/>

+ <span style="color:red">04/2021:</span> Our team L3IRIS has won the Task 1, the flagship task of the <span style="color:blue">[ ICDAR 2021 Competition on Historical Map Segmentation](https://icdar21-mapseg.github.io/)</span>. We will release the prediction code with the pre-trained model of our method soon on [here](https://gitlab.univ-lr.fr/nnguye02/weakbiseg)<br/>

+ <span style="color:red">03/2021:</span> An <span style="color:blue">[article](https://vnexpress.net/tro-choi-quyen-luc-4243108.html)</span> (in Vietnamese) on the power of social networks like Facebook appeared in the Opinion column of VnExpress (one of the most important media in Vietnam).<br/>

+ <span style="color:red">01/2021:</span> The <span style="color:blue">[official website](https://emoreccom.univ-lr.fr)</span> and <span style="color:blue">[Codalab site](https://competitions.codalab.org/competitions/27884)</span> for our challenge EmoRecCom are now available.<br/>

+ <span style="color:red">12/2020:</span> The <span style="color:blue">[official website](https://www.rivf2021-mc-ocr.vietnlp.com/)</span> and <span style="color:blue">[Codalab site](https://competitions.codalab.org/competitions/27798)</span> for our challenge MC-OCR are now available.<br/>

+ <span style="color:red">11/2020:</span> Our MC-OCR (Mobile-Captured Image Document Recognition for Vietnamese Receipts) challenge proposal is accepted at  <span style="color:blue">[RIVF2021](http://fit.mta.edu.vn/rivf2021/)</span>! (A collaboration work with researchers at the Umea university, Oracle Australian, Purchease company).  <br/>

+ <span style="color:red">10/2020:</span> 1 paper is accepted at <span style="color:blue">MANPU@ICPR2021!</span><br/>

<!-- + <span style="color:red">10/2020:</span> The project <span style="color:blue">DocIntel</span> is submitted for the KC4.0 Innovation Fund of the Vietnamese Ministry of Science and Technology.<br/> -->

+ <span style="color:red">09/2020:</span> Our EmoRecCom (Multimodal Emotion Recognition on Comics scenes) challenge proposal is accepted at <span style="color:blue">[ICDAR2021!](https://icdar2021.org/)</span>  (A collaboration with <span style="color:blue">[Deep Data Mining](https://www.umu.se/en/research/groups/deep-data-mining/)</span>  research group at the Umea university, Sweden)<br/>

+ <span style="color:red">06/2020:</span> 1 article accepted at <span style="color:blue">[Neural Networks](https://www.journals.elsevier.com/neural-networks)</span> (Elsevier) , Q1 (IF 5.786) <br/>

+ <span style="color:red">04/2020:</span> <span style="color:blue">[#Hack4Growth,](https://www.hack4growth.org/en).</span> the international innovation competition, has completed its first phase. We also started an extension of #Hack4Growth - Covid Endgame As a response to the Covid-19 pandemic. This track is aimed at seeking solutions to problems caused by the pandemic.  <br/>

+ <span style="color:red">03/2020:</span> VILinks event is canceled due to the spread of coronavirus worldwide. <br/>

+ <span style="color:red">02/2020:</span> 1 paper accepted at JCDL2020, CORE rank A*. <br/>

<!-- + <span style="color:red">02/2020:</span> I obtained <span style="color:blue">my (first) qualification MCF in Section 27.</span> <br/> -->

+ <span style="color:red">01/2020:</span> Sending out invitations for speakers and sponsors for <span style="color:blue">[VILinks2020](https://www.vietnaminnovationlinks.org).</span> <br/>
We are looking for high profile innovators to speak at VILinks, the international innovation summit in VIetnam on 06-08 August 2020.

+ <span style="color:red">12/2019:</span> Looking for 2 interns in Computer Vision and Machine Learning, 1 PhD student on comic book image analysis.

<!-- + <span style="color:red">10/2019:</span> Vietnam trip -->

+ <span style="color:red">09/2019:</span> 2 journal papers accepted at IJDAR (Q2). Conference trip to ICDAR2019 at Sydney, Australia.

<!-- + <span style="color:red">05/2019:</span> www.brickinup.com is shutdown. -->

+ <span style="color:red">04/2019:</span> 4 papers accepted at ICDAR2019, CORE rank A. (1 oral, 1 poster and 2 workshops papers).

+ <span style="color:red">03/2019:</span> Participation the [Vietnam Global Leaders Forum](https://www.vietnamgloballeaders.org) at Paris, France

+ <span style="color:red">01/2019:</span> Conference trip to Thellesolniaki, Grece (MMM2019).

+ <span style="color:red">11/2018:</span> 1 oral paper accepted at the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications VISSAP/VISIGRAPP. CORE rank B.

+ <span style="color:red">10/2018:</span> 1 oral paper accepted at the MANPU workshop at the International Conference on Multimedia Modeling (2019). CORE rank C.

+ <span style="color:red">08/2018:</span> Participation to the Vietnam Innovation Networks (Among 100 Vietnamese scientists and experts, invited by the Vietnam govenerment).

+ <span style="color:red">08/2018:</span> 1 oral paper accepted at the International Conference on Asian Digital Libraries, CORE rank A.

+ <span style="color:red">05/2018:</span> 1 oral paper accepted at the ACM/IEEE Joint Conference on Digital Libraries (JCDL), Core rank A*

<!-- + <span style="color:red">03/2018:</span> 1 journal paper accepted at J. Imaging (MDPI). -->

---
